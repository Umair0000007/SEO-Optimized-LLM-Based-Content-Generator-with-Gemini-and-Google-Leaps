{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.amazon.com/Stun-Guns/b?ie=UTF8&node=7824770011', 'https://community.southwest.com/t5/Travel-Policies/SouthWest-Stun-Gun-Policy/td-p/111865', 'https://www.amazon.com/VIPERTEK-VTS-T03-Aluminum-Rechargeable-Flashlight/dp/B0CQVF3WGS', 'https://www.reddit.com/r/homedefense/comments/17x7t4b/stun_gun_or_taser/', 'https://www.sabrered.com/stun-guns-personal-security/', 'https://steamcommunity.com/app/2073850/discussions/0/4030224579615086269/', 'https://www.instagram.com/stungunjen/', 'https://steamcommunity.com/app/480490/discussions/0/1334600128974537973/', 'https://www.tsa.gov/travel/security-screening/whatcanibring/items/stun-gunsshocking-devices', 'https://steamcommunity.com/app/538030/discussions/0/3805029995432697732/']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_top_articles(keyword):\n",
    "    search_url = f\"https://www.googleapis.com/customsearch/v1?key={key}&cx={cx}&q=stun gun\"\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        search_results = response.json()\n",
    "        urls = [item['link'] for item in search_results.get('items', [])]\n",
    "        return urls\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "urls = get_top_articles(\"street crime\")\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Street_crime'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: No title found\n",
      "\n",
      "Headings:\n",
      "H1:\n",
      "H2:\n",
      "H3:\n",
      "\n",
      "\n",
      "Title: \n",
      "\tSouthWest Stun Gun Policy - The Southwest Airlines Community\n",
      "\n",
      "\n",
      "Headings:\n",
      "H1:\n",
      "  - Southwest Airlines Community\n",
      "H2:\n",
      "  - SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: SouthWest Stun Gun Policy\n",
      "  - Re: Stun gun and pepper spray\n",
      "  - SouthWest Stun Gun Policy\n",
      "H3:\n",
      "  - Quick Links\n",
      "  - Community Champions\n",
      "  - Need help?\n",
      "  - Subscribe\n",
      "  - Connect with us\n",
      "\n",
      "\n",
      "Title: Amazon.com\n",
      "\n",
      "Headings:\n",
      "H1:\n",
      "H2:\n",
      "H3:\n",
      "\n",
      "\n",
      "Error: Unable to fetch the URL https://www.sabrered.com/stun-guns-personal-security/. Exception: HTTPSConnectionPool(host='www.sabrered.com', port=443): Max retries exceeded with url: /stun-guns-personal-security/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')))\n",
      "Skipped URL: https://www.sabrered.com/stun-guns-personal-security/ due to an error.\n",
      "\n",
      "Title: Remove the Stun Gun :: THE FINALS General Discussions\n",
      "\n",
      "Headings:\n",
      "H1:\n",
      "H2:\n",
      "  - Report this post\n",
      "H3:\n",
      "  - THE FINALS\n",
      "\n",
      "\n",
      "Title: Stun Gun -- Why Bother? :: Prey General Discussions\n",
      "\n",
      "Headings:\n",
      "H1:\n",
      "H2:\n",
      "  - Report this post\n",
      "H3:\n",
      "  - Prey\n",
      "\n",
      "\n",
      "Title: Stun Guns/Shocking Devices | Transportation Security Administration\n",
      "\n",
      "Headings:\n",
      "H1:\n",
      "  - Stun Guns/Shocking Devices\n",
      "H2:\n",
      "  - Travel\n",
      "  - Travel\n",
      "  - Footer Top\n",
      "H3:\n",
      "\n",
      "\n",
      "Title: Stun Baton vs Stun Gun :: Xenonauts 2 Gameplay Discussions\n",
      "\n",
      "Headings:\n",
      "H1:\n",
      "H2:\n",
      "  - Report this post\n",
      "H3:\n",
      "  - Xenonauts 2\n",
      "\n",
      "\n",
      "Collected article structures: [{'title': 'No title found', 'headings': {'H1': [], 'H2': [], 'H3': []}}, {'title': '\\n\\tSouthWest Stun Gun Policy - The Southwest Airlines Community\\n', 'headings': {'H1': ['Southwest Airlines Community'], 'H2': ['SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: SouthWest Stun Gun Policy', 'Re: Stun gun and pepper spray', 'SouthWest Stun Gun Policy'], 'H3': ['Quick Links', 'Community Champions', 'Need help?', 'Subscribe', 'Connect with us']}}, {'title': 'Amazon.com', 'headings': {'H1': [], 'H2': [], 'H3': []}}, {'title': 'Remove the Stun Gun :: THE FINALS General Discussions', 'headings': {'H1': [], 'H2': ['Report this post'], 'H3': ['THE FINALS']}}, {'title': 'Stun Gun -- Why Bother? :: Prey General Discussions', 'headings': {'H1': [], 'H2': ['Report this post'], 'H3': ['Prey']}}, {'title': 'Stun Guns/Shocking Devices | Transportation Security Administration', 'headings': {'H1': ['Stun Guns/Shocking Devices'], 'H2': ['Travel', 'Travel', 'Footer Top'], 'H3': []}}, {'title': 'Stun Baton vs Stun Gun :: Xenonauts 2 Gameplay Discussions', 'headings': {'H1': [], 'H2': ['Report this post'], 'H3': ['Xenonauts 2']}}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Function to get article schema\n",
    "def get_article_schema(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # This will raise an HTTPError for bad responses\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract title\n",
    "        title = soup.title.string if soup.title else 'No title found'\n",
    "\n",
    "        # Extract headings\n",
    "        headings = {'H1': [], 'H2': [], 'H3': []}\n",
    "        for h in headings.keys():\n",
    "            headings[h] = [element.get_text().strip() for element in soup.find_all(h.lower())]\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'headings': headings\n",
    "        }\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error: Unable to fetch the URL {url}. Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "# List of social media domains to filter out\n",
    "social_media_domains = [\n",
    "    'facebook.com',\n",
    "    'twitter.com',\n",
    "    'linkedin.com',\n",
    "    'instagram.com',\n",
    "    'quora.com',\n",
    "    'reddit.com',\n",
    "    'tiktok.com'\n",
    "    'amazon.com'\n",
    "]\n",
    "\n",
    "# Function to check if a URL belongs to social media\n",
    "def is_social_media_url(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    netloc = parsed_url.netloc.lower()\n",
    "    return any(domain in netloc for domain in social_media_domains)\n",
    "\n",
    "# Filter URLs to remove social media URLs\n",
    "filtered_urls = [url for url in urls if not is_social_media_url(url)]\n",
    "\n",
    "# Initialize the article_structure list\n",
    "article_structure = []\n",
    "\n",
    "# Process remaining URLs\n",
    "for url in filtered_urls:\n",
    "    structure = get_article_schema(url)\n",
    "    if structure:\n",
    "        article_structure.append(structure)\n",
    "        print(f\"Title: {structure['title']}\\n\")\n",
    "        print(\"Headings:\")\n",
    "        for tag, texts in structure['headings'].items():\n",
    "            print(f\"{tag}:\")\n",
    "            for text in texts:\n",
    "                print(f\"  - {text}\")\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Skipped URL: {url} due to an error.\\n\")\n",
    "\n",
    "# Optional: To show the collected structures\n",
    "print(f\"Collected article structures: {article_structure}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southwest Airlines Community, Stun Guns/Shocking Devices\n",
      "SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: SouthWest Stun Gun Policy, Re: Stun gun and pepper spray, SouthWest Stun Gun Policy, Report this post, Report this post, Travel, Travel, Footer Top, Report this post\n",
      "Quick Links, Community Champions, Need help?, Subscribe, Connect with us, THE FINALS, Prey, Xenonauts 2\n"
     ]
    }
   ],
   "source": [
    "all_titles = []\n",
    "all_head1 = []\n",
    "all_head2 = []\n",
    "all_head3 = []\n",
    "for h1 in article_structure:\n",
    "    all_head1.append(h1['headings']['H1']) \n",
    "for h2 in article_structure:\n",
    "    all_head2.append(h2['headings']['H2'])\n",
    "for h3 in article_structure:\n",
    "    all_head3.append(h3['headings']['H3'])\n",
    "for titles in article_structure:\n",
    "    all_titles.append(titles['title'])\n",
    "\n",
    "# Flatten the list using a list comprehension\n",
    "head1_list = [item for sublist in all_head1 for item in sublist]\n",
    "# Join the flattened list into a comma-separated string\n",
    "head1 = ', '.join(head1_list)\n",
    "\n",
    "# Flatten the list using a list comprehension\n",
    "head2_list = [item for sublist in all_head2 for item in sublist]\n",
    "# Join the flattened list into a comma-separated string\n",
    "head2 = ', '.join(head2_list)\n",
    "\n",
    "# Flatten the list using a list comprehension\n",
    "head3_list = [item for sublist in all_head3 for item in sublist]\n",
    "# Join the flattened list into a comma-separated string\n",
    "head3 = ', '.join(head3_list)\n",
    "\n",
    "print(head1)\n",
    "print(head2)\n",
    "print(head3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: '/kaggle/input/mistral/pytorch/7b-v0.1-hf/1'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sc\\rag\\Lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\sc\\rag\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:111\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 111\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sc\\rag\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:159\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/input/mistral/pytorch/7b-v0.1-hf/1'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      5\u001b[0m         model_name,\n\u001b[0;32m      6\u001b[0m         load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sc\\rag\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:804\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[1;32m--> 804\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[0;32m    806\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sc\\rag\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:637\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[1;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m    634\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[0;32m    636\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 637\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    654\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sc\\rag\\Lib\\site-packages\\transformers\\utils\\hub.py:462\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    464\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[1;31mOSError\u001b[0m: Incorrect path_or_model_id: '/kaggle/input/mistral/pytorch/7b-v0.1-hf/1'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "model_name = \"/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        load_in_4bit=True,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install backend dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [32 lines of output]\n",
      "      Collecting distribute\n",
      "        Using cached distribute-0.7.3.zip (145 kB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— Preparing metadata (pyproject.toml) did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [6 lines of output]\n",
      "            usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "               or: setup.py --help [cmd1 cmd2 ...]\n",
      "               or: setup.py --help-commands\n",
      "               or: setup.py cmd --help\n",
      "      \n",
      "            error: invalid command 'dist_info'\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: metadata-generation-failed\n",
      "      \n",
      "      Ã— Encountered error while generating package metadata.\n",
      "      â•°â”€> See above for output.\n",
      "      \n",
      "      note: This is an issue with the package mentioned above, not pip.\n",
      "      hint: See above for details.\n",
      "      \n",
      "      [notice] A new release of pip is available: 24.0 -> 24.1\n",
      "      [notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install backend dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in c:\\users\\sc\\rag\\lib\\site-packages (8.24.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sc\\rag\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sc\\rag\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sc\\rag\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sc\\rag\\lib\\site-packages (from stack-data->ipython) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sc\\rag\\lib\\site-packages (from stack-data->ipython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sc\\rag\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sc\\rag\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install ipython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m      7\u001b[0m load_dotenv()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "!pip install dotenv\n",
    "!pip install ipython\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "google_api_key = os.getenv(\"Google_API_KEY\")\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"\n",
    "    Loads a Gemini-Pro model for natural language processing.\n",
    "\n",
    "    Returns:\n",
    "    - dict: The response object from the model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt = \"Write a 1 line story about a magic backpack.\"\n",
    "        # Assuming the method to generate text is 'generate_text'\n",
    "        response = genai.generate_text(model=\"gemini-pro\", prompt=prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to model:\", e)\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = load_model()\n",
    "    if result:\n",
    "        print(result)  # Print the whole response to inspect its structure\n",
    "    else:\n",
    "        print(\"Failed to generate content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
